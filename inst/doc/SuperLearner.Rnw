% \VignetteIndexEntry{SuperLearner Manual}
% \VignetteDepends{SuperLearner}
% \VignettePackage{SuperLearner}
\documentclass[11pt, nojss]{jss}

\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{longtable}

\DeclareMathOperator{\argmax}{\arg\max}
\DeclareMathOperator{\argmin}{\arg\min}

%% need no \usepackage{Sweave.sty}
\SweaveOpts{keep.source=TRUE}
\SweaveOpts{eps = FALSE, pdf = TRUE}  % only produce pdf
\SweaveOpts{width=6, height=4}  % default figure size in R
\setkeys{Gin}{width=0.85\textwidth}   % default figure size in latex
<<setup, echo=false, results = hide>>=
options(width=60)
if(!file.exists('plots')) dir.create('plots')
# options(continue=' ')
@
\SweaveOpts{prefix.string = plots/fig}

\title{\texttt SuperLearner}
\author{Eric C. Polley\\ Biometric Research Branch\\ National Cancer Institute \And Mark J. van der Laan\\ Division of Biostatistics\\ University of California, Berkeley }
\Plainauthor{Eric C. Polley, Mark J. van der Laan}
\Plaintitle{The SuperLearner Package}
\Address{
  Eric Polley\\
  Biometric Research Branch\\
  National Cancer Institute\\
  E-mail: \email{eric.polley@nih.gov}\\
  URL: \url{http://linus.nci.nih.gov/}\\
  
	Mark van der Laan\\
	Division of Biostatistics\\
	University of California, Berkeley\\
	E-mail: \email{laan@berkeley.edu}\\
	URL: \url{http://www.stat.berkeley.edu/~laan/}
}
\Abstract{
	An \proglang{R} package for the Super Learner \cite{superlearner:2007} is presented.
}
\Keywords{prediction models, cross-validation, \proglang{R}}
\Plainkeywords{prediction models, cross-validation, R}

\begin{document}

\maketitle

\section{Introduction}
This vignette explains how to use the \pkg{SuperLearner} \proglang{R} package. The \pkg{SuperLearner} package provides a syntax and structure to implement the super learner algorithm \cite{superlearner:2007}.  A characteristic of the super learner algorithm is the ability to combine many different prediction algorithms together and let the data decide on the optimal ensemble.  \proglang{R} is the perfect language for such an algorithm because of the wealth of available prediction algorithms already available in the community.  One problem is that prediction algorithms do not have a common syntax, so one of the goals of the \pkg{SuperLearner} package is to translate these prediction algorithms into a common syntax to allow for easy programming of the super learner.

\section{The Super Learner Algorithm}

   \begin{longtable}{llll @{} }
	\caption{Details of prediction algorithm wrappers \label{tab:predAlg}} \\
	   \toprule
		\textbf{Function} & \textbf{Package} & \textbf{Tuning Parameters} & \textbf{Description} \tabularnewline
		\midrule
	\endhead
	
	\midrule
	\multicolumn{4}{c}{(Continued on next page)}
	\endfoot
	
	\bottomrule
	\endlastfoot
	
		\code{bagging} & \pkg{ipred} & \code{nbagg} & Bagging CART trees \\*
					&				& \code{minsplit} \\*
					&				& \code{cp} \\*
					&				& \code{maxdepth}\tabularnewline
		\code{bart}	& \pkg{BayesTree} & \code{ntree} & Bayesian Regression Trees \\*
					&				& \code{sigdf} \\*
					&				& \code{sigquant}\\*
					&				& \code{k}\\*
					&				& \code{power}\\*
					&				& \code{base}\\*
					&				& \code{ndpost}\\*
					&				& \code{nskip}\tabularnewline
	\code{bayesglm} & \pkg{arm}	& \code{prior.mean} & Bayesian glm \\*
					&				& \code{prior.scale}\\*
					&				& \code{prior.df}\tabularnewline
	\code{cforest}	& \pkg{party}	& \code{ntree} & Conditional Tree Forest\\*
	 				& 				& \code{mtry}\\*
					&				& \code{mincriterion}\\*
					&				& \code{teststat}\\*
					&				& \code{testtype}\\*
					&				& \code{replace}\\*
					&				& \code{fraction}\tabularnewline
	\code{cv.spls} 	& \pkg{spls}	& \code{K} & Sparse partial least squares \\*
					&				& \code{eta}\tabularnewline
	\code{DSA} 	& \pkg{DSA} 	& \code{maxsize} & Deletion\textbackslash Substitution\textbackslash Addition\\*
					&				& \code{maxorderint} \\*
					&				& \code{maxsumofpow} \\*
					&				& \code{Dmove} \\*
					&				& \code{Smove} \\*
					&				& \code{vfold} \tabularnewline
	\code{earth}	& \pkg{earth}	& \code{degree} & Adaptive Regression Splines \\*
					&				& \code{penalty} \\*
					&				& \code{nk} \\*
					&				& \code{thresh} \\*
					&				& \code{minspan} \\*
					&				& \code{newvar.penalty} \\*
					&				& \code{fast.k} \\*
					&				& \code{fast.beta} \\*
					&				& \code{nfold} \\*
					&				& \code{pmethod} \tabularnewline
	\code{gam}		& \pkg{gam}		& \code{deg.gam} & Generalized additive model \tabularnewline
	\code{gbm}		& \pkg{gbm}		& \code{gbm.trees} & Gradient boosting \\*
					&				& \code{interaction.depth} \\*
					&				& \code{cv.folds} \\*
					&				& \code{shrinkage} \\*
					&				& \code{n.minobsinnode} \\*
					&				& \code{bag.fraction} \\*
					&				& \code{train.fraction}\tabularnewline
	\code{glm}		& \pkg{stats}	& -- & Generalized linear model \tabularnewline
	\code{glmnet}	& \pkg{glmnet}	& \code{alpha} & Elastic Net \\*
					&				& \code{lambda}\\*
					&				& \code{nlambda}\\*
					&				& \code{lambda.min}\\*
					&				& \code{dfmax}\\*
					&				& \code{type}\tabularnewline
	\code{knn}		& \pkg{class}	& \code{k} & k-Nearest neighbors\\*
					&				& \code{use.all}\tabularnewline
	\code{loess}	& \pkg{stats}	& \code{span} & Local polynomial regression\\*
					&				& \code{family}\\*
					&				& \code{degree}\tabularnewline
	\code{logreg}	& \pkg{LogicReg} & \code{ntrees} & Logic regression\\*
					&				& \code{nleaves}\\*
					&				& \code{select}\\*
					&				& \code{penalty}\\*
					&				& \code{kfold}\\*
					&				& \code{control}\tabularnewline
	\code{mars}		& \pkg{mda}		& \code{degree} & Adaptive Regression Splines \\*
					&				& \code{nk} \\*
					&				& \code{penalty} \\*
					&				& \code{thresh} \\*
					&				& \code{prune} \\*
					&				& \code{forward.step} \tabularnewline
	\code{nnet}		& \pkg{nnet}	& \code{size} & Neural network\\*
					&				& \code{decay}\\*
					&				& \code{rang}\tabularnewline
	\code{polymars}	& \pkg{polspline} & \code{maxsize} & Adaptive polynomial splines \\*
					&				& \code{gcv}\\*
					&				& \code{additive}\\*
					&				& \code{knots}\\*
					&				& \code{know.space} \tabularnewline
	\code{polyclass} & \pkg{polspline} & \code{maxdim} & Polychotomous regression \\*
					&				& \code{cv}\\*
					&				& \code{additive}\tabularnewline
	\code{randomForest} & \pkg{randomForest} & \code{ntree} & Random Forest \\*
					&				& \code{mtry}\\*
					&				& \code{nodesizes}\\*
					&				& \code{sampsize}\\*
					&				& \code{replace}\\*
					&				& \code{maxnodes}\tabularnewline
	\code{Ridge}	& \pkg{MASS}	& \code{lambda} & Ridge regression\tabularnewline
	\code{rpart}	& \pkg{rpart}	& \code{cp} & Regression tree\\*
					&				& \code{minsplit}\\*
					&				& \code{xval}\\*
					&				& \code{maxdepth}\\*
					&				& \code{minbucket}\tabularnewline
	\code{step}		& \pkg{stats}	& \code{scope} & Stepwise regression\\*
	 				&				& \code{scale}\\*
					&				& \code{direction}\\*
					&				& \code{steps}\\*
					&				& \code{k}\tabularnewline
	\code{step.plr} & \pkg{stepPlr} & \code{type} & Stepwise penalized logistic\\*
					&				& \code{lambda}\\*
					&				& \code{cp}\\*
					&				& \code{max.terms}\tabularnewline
	\code{svm}		& \pkg{e1071}	& \code{type} & Support vector machine\\*
					&				& \code{kernel}\\*
					&				& \code{nu}\\*
					&				& \code{degree}\\*
					&				& \code{gamma}\\*
					&				& \code{coef0}\\*
					&				& \code{cost}\\*
					&				& \code{cachesize}\\*
					&				& \code{tolerance}\\*
					&				& \code{epsilon}\\*
					&				& \code{cross}\tabularnewline
\end{longtable}


\section{Using the SuperLearner Package}
<<>>=
library(SuperLearner)
@
\subsection{Creating prediction wrappers}
A full list of the built-in prediction wrappers can be found with the function:
<<>>=
listWrappers(what = 'SL')
@
And the included template creator:
<<>>=
write.SL.template(file = '')
@
\subsection{Creating screening wrappers}
A full list of the built-in screening wrappers can be found with the function:
<<>>=
listWrappers(what = 'screen')
@
And the included template creator:
<<>>=
write.screen.template(file = '')
@

\subsection{Creating methods wrappers}
The included template creator:
<<>>=
write.method.template(file = '')
@

\bibliography{SLrefs}

\section{Computing Environment}
<<echo=F, results=tex>>=
s <- toLatex(sessionInfo())
cat(s[-grep('Locale',s)], sep='\n')
@

\end{document}
